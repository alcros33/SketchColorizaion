{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform images to sketches using diferent methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, gc, math, random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize, Compose, Pad\n",
    "import fastai.basics as faib\n",
    "import fastai.vision.all as fv\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "from sketch_keras import SketchKeras\n",
    "from sketch_simplification import SimplifyModel\n",
    "from anime2sketch import A2SModel\n",
    "from xdog import XDOG\n",
    "\n",
    "to_image = ToPILImage()\n",
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketch Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_pad_tensor(img, size):\n",
    "    h, w = img.shape\n",
    "    nsize = [size, size]\n",
    "    if h>w:\n",
    "        nsize[1] = int(size / h * w)\n",
    "    else:\n",
    "        nsize[0] = int(size / w * h)\n",
    "    tens = to_tensor(img.resize(nsize))\n",
    "    tens = Pad((0, 0, 512-tens.shape[2], 512-tens.shape[1]))(tens)\n",
    "    return tens, nsize[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = SketchKeras(25,3,0).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_to_lineart(imgfiles, thresh = 0.0):\n",
    "    global save_folder\n",
    "    if isinstance(imgfiles, (str, Path)):\n",
    "        imgfiles = [imgfiles]\n",
    "    \n",
    "    imgfiles = [Path(i) for i in imgfiles]\n",
    "    \n",
    "    tensors, sizes, nsizes = [], [], []\n",
    "    for f in imgfiles:\n",
    "        im = Image.open(f).convert(\"RGB\")\n",
    "        sizes.append(im.shape)\n",
    "        t, ns = resize_pad_tensor(im, 512)\n",
    "        tensors.append(t)\n",
    "        nsizes.append(ns)\n",
    "    \n",
    "    x = torch.stack(tensors).cuda()\n",
    "    with torch.no_grad():\n",
    "        pred = keras_model(x).cpu()\n",
    "    \n",
    "    for p, ns, siz, f in zip(pred, nsizes, sizes, imgfiles):\n",
    "        outp = to_image(p[:,:ns[0],:ns[1]]).resize(siz[::-1])\n",
    "        outp.save(str(save_folder/f.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_bw_tensor(fname):\n",
    "    return to_tensor(Image.open(fname).convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdog_model = XDOG(4.5, 0.4, 0.95, -0.7, 1e9, 25).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xdog_to_lineart(imgfiles):\n",
    "    global save_folder\n",
    "    if isinstance(imgfiles, (str, Path)):\n",
    "        imgfiles = [imgfiles]\n",
    "    \n",
    "    imgfiles = [Path(i) for i in imgfiles]\n",
    "    x = torch.stack(list(map(open_bw_tensor, imgfiles))).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = xdog_model(x).cpu()\n",
    "    \n",
    "    for p, f in zip(x,  imgfiles):\n",
    "        outp = to_image(p)\n",
    "        outp.save(str(save_folder/f.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_model = SimplifyModel().cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simp_to_lineart(imgfiles, immean=0.9664114577640158 , imstd=0.0858381272736797):\n",
    "    global save_folder\n",
    "    if isinstance(imgfiles, (str, Path)):\n",
    "        imgfiles = [imgfiles]\n",
    "    imgfiles = [Path(i) for i in imgfiles]\n",
    "    imgs = torch.stack(list(map(open_bw_tensor, imgfiles))).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = simplify_model(imgs).cpu()\n",
    "        pil_out = [to_image(o) for o in out]\n",
    "    \n",
    "    for name, i_out in zip(imgfiles, pil_out):\n",
    "        i_out.save(str(save_folder/name.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime2Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2s_model = A2SModel().eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2s_to_lineart(imgfiles):\n",
    "    global save_folder\n",
    "    if isinstance(imgfiles, (str, Path)):\n",
    "        imgfiles = [imgfiles]\n",
    "    imgfiles = [Path(i) for i in imgfiles]\n",
    "    \n",
    "    imgs = [Image.open(f).convert(\"RGB\") for f in imgfiles]\n",
    "    \n",
    "    tensors, sizes, nsizes = [], [], []\n",
    "    for im in imgs:\n",
    "        sizes.append(im.shape)\n",
    "        t, ns = resize_pad_tensor(im, 512)\n",
    "        tensors.append(t)\n",
    "        nsizes.append(ns)\n",
    "    \n",
    "    x = torch.stack(tensors).cuda()\n",
    "    with torch.no_grad():\n",
    "        pred = a2s_model(x).cpu()\n",
    "        \n",
    "    for p, ns, siz, f in zip(pred, nsizes, sizes, imgfiles):\n",
    "        outp = to_image(p[:,:ns[0],:ns[1]]).resize(siz[::-1])\n",
    "        outp.save(str(save_folder/f.stem)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamble(imgfiles):\n",
    "    global save_folder\n",
    "    if isinstance(imgfiles, (str, Path)):\n",
    "        imgfiles = [imgfiles]\n",
    "    imgfiles = [Path(i) for i in imgfiles]\n",
    "    \n",
    "    imgs = [Image.open(f).convert(\"RGB\") for f in imgfiles]\n",
    "    \n",
    "    tensors, sizes, nsizes = [], [], []\n",
    "    for im in imgs:\n",
    "        sizes.append(im.shape)\n",
    "        t, ns = resize_pad_tensor(im, 512)\n",
    "        tensors.append(t)\n",
    "        nsizes.append(ns)\n",
    "    \n",
    "    x = torch.stack(tensors).cuda()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        w = random.random()\n",
    "        pred = a2s_model(x)*w + keras_model(x)*(1-w)\n",
    "        pred = pred.cpu()\n",
    "        \n",
    "    for p, ns, siz, f in zip(pred, nsizes, sizes, imgfiles):\n",
    "        outp = to_image(p[:,:ns[0],:ns[1]]).resize(siz[::-1])\n",
    "        outp.save(str(save_folder/f.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(iterable, n):\n",
    "    curr = []\n",
    "    for it in iterable:\n",
    "        curr.append(it)\n",
    "        if len(curr) == n:\n",
    "            yield curr[:]\n",
    "            curr = []\n",
    "    if curr:\n",
    "        yield curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fv.get_image_files(\"path/to/images\")\n",
    "save_folder = Path(\"where/to/save\")\n",
    "save_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs in progress_bar(list(chunks(files, 16))):\n",
    "    ensamble(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fastai",
   "language": "python",
   "name": "fastaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
